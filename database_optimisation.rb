Rails Database Optimizations (Basic and general optimization. Part -1 )
=======================================================================
âž¤ Select Only What You Need:
    Rails by default loads all columns with SELECT *. Bad for performance when you only need 1-2 fields.
      User.select(:id, :email).where(active: true)
      SELECT "users"."id", "users"."email" FROM "users" WHERE "users"."active" = TRUE

âž¤ Avoid N+1 Queries Using includes, eager_load, preload

âž¤ Use .pluck Instead of .map(&:field)
    User.where(active: true).map(&:email) => Inefficient as it loads entire User objects just to get emails.
    User.where(active: true).pluck(:email) => Optimized

âž¤ Use .exists? Instead of .present? or .any?
    User.where(email: 'x@example.com').present? => Inefficient as it loads records into memory.
    User.exists?(email: 'x@example.com') => Optimized

âž¤ Batch Processing with .find_each / .in_batches
  ðŸ”¸Slow & Memory-heavy:
      User.all.each do |user|
        process(user)
      end
    
  ðŸ”¸Efficient:
      User.find_each(batch_size: 100) do |user|
        process(user)
      end

âž¤ Use counter_cache to Avoid Count Queries
    N+1 Count:
      user.posts.count => Executes SQL each time.

    The counter_cache (column of type int) value is stored in the parent table (i.e., the table that has has_many). Suppose:
      A User has_many posts
      A Post belongs_to a user
    So, we add the posts_count column to the users table:
      class User < ApplicationRecord
        has_many :posts
      end

      class Post < ApplicationRecord
        belongs_to :user, counter_cache: true
      end      
    Then just use:
      user.posts_count

âž¤ Use scoped / readonly for Security
    User.readonly.first.update(name: "New") => Avoid accidental updates
    # => ActiveRecord::ReadOnlyRecord error

âž¤ Use EXPLAIN ANALYZE in SQL to Detect Slow Queries
    In Rails console:
      ActiveRecord::Base.connection.execute("EXPLAIN ANALYZE SELECT * FROM users WHERE email = 'x@example.com'")
    For a query object:
      User.where(email: 'x@example.com').explain


Database Indexing in Rails (Part - 2)
=====================================
 - Think of a database index like the index of a book â€” it helps find records fast without scanning the entire table.
 - Instead of searching 1 million rows, it jumps right to where the data lives.

  Types of Indexes
  ----------------
  â•°â”ˆâž¤ Single-Column Index
        add_index :users, :email => Add index in users table on email column.
        
        This will optimize => User.find_by(email: "a@example.com")

  â•°â”ˆâž¤ Multi-Column (Composite) Index 
        NOTE: In composite Index, order matters.

        add_index :orders, [:user_id, :status] => Add index in orders table on user_id  and statsu column together.
        This will optimize => Order.where(user_id: 1, status: 'shipped')

  â•°â”ˆâž¤ Unique Index
        Prevents duplicate records at the DB level.
        add_index :users, :email, unique: true
    
  â•°â”ˆâž¤ Partial Index
        add_index :orders, :user_id, where: "status = 'completed'"

        Only indexes completed orders â†’ lighter & faster for certain queries.
          Order.where(user_id: 1, status: 'completed') # uses index

  â•°â”ˆâž¤ Function/Expression Index (PostgreSQL only)
        add_index :users, "LOWER(email)", name: "index_users_on_lower_email"

        Now this is optimized:
        User.find_by("LOWER(email) = ?", input.downcase)
      
  â•°â”ˆâž¤ Foreign Key Indexes
        Always index foreign keys:
          t.references :user, index: true, foreign_key: true
        Optimizes:
          Joins
          WHERE user_id = ?
          Eager loading

  âž¤ Use EXPLAIN to Check If Index Is Used
      In Rails console:
        User.where(email: "x@x.com").explain
      Sample output:
        Index Scan using index_users_on_email on users
    
  âž¤ Over-Indexing Is Dangerous
      Too many indexes will results in
       ðŸ”¸Slower INSERT/UPDATE
       ðŸ”¸Higher storage usage
       ðŸ”¸More bloat

      ðŸŽ¯ Golden Rule: Index only what you query.

  âž¤ How to Know What to Index
      Ask yourself:
  
        | If your query has... | You need index on... |
        | -------------------- | -------------------- |
        | WHERE condition      | the filtered columns |
        | JOIN condition       | the joining column   |
        | ORDER BY             | the sorted column    |
        | Foreign keys         | always index them    |


Transactions and Isolation Levels in Rails (Advance)
======================================================================
  âž¤ These are critical concepts when multiple users hit your app at once â€” e.g., ticket bookings, payments, inventory updates.
  
  âž¤ What Is a Transaction?
     - A transaction groups multiple database operations into one atomic unit:
     - Either all succeed or all fail â€” never partial. It prevents from data inconsistency!

      ActiveRecord::Base.transaction do
        user.update!(balance: user.balance - 100)
        order.update!(status: 'paid')
      end

    - If any .update! fails, none of the changes are committed.

  âž¤ What Are Isolation Levels?
     - Isolation Levels are part of Database Transactions â€” a fundamental concept to ensure data integrity when multiple users access the database at the same time.

     - when we write:
        ActiveRecord::Base.transaction do
          user.update!(balance: user.balance - 100)
          account.update!(total: account.total + 100)
        end

        Here, we are creating a transaction â€” a block that should:
          ðŸ”¸Complete fully (commit), or
          ðŸ”¸Be undone entirely (rollback) if anything fails

        Now imagine many users do this at the same time.
         To avoid data inconsistencies (like overspending), databases isolate each transaction from others transaction using "Isolation Levels".

      - There are 4 types of Isolation Levels and there are 3 kinds of problems that may occur during concurrent transactions.

  âž¤ Three kinds of problems during concurrent transactions:
     â•°â”ˆâž¤ Dirty Read:
          - A transaction reads data written by another uncommitted transaction

     â•°â”ˆâž¤ Non-Repeatable Read:
          - A row you read once changes if you read it again in the same transaction

     â•°â”ˆâž¤ Phantom Read:
          - You run a query, and rerun it and get different rows (e.g. new rows added)
      
  âž¤ Four types of Isolation Levels:
     â•°â”ˆâž¤ Read Uncommitted (Lowest isolation): Rails does not use this. It is very unsafe.
          ðŸ”¸Dirty Read allowed â†’ Can read uncommitted data from others transaction.
          ðŸ”¸Non-repeatable Read â†’ Same row may change mid-transaction.
          ðŸ”¸Phantom Read â†’ Query result may change due to new inserts.

     â•°â”ˆâž¤ Read Committed: (Rails default in PostgreSQL)
          ðŸ”¸No Dirty Reads â†’ Cannot see uncommitted data
          ðŸ”¸Non-Repeatable Reads â†’ A row you read may change if someone commits new data i.e by other transaction.
          ðŸ”¸Phantom Read â†’ A repeated query may return new rows.

          â†’ You may get a different value on reload even inside the same transaction. This is non-repeatable read.
          ActiveRecord::Base.transaction do
            product = Product.find(1)
            # Suppose User B updates product price at this stage.
            product.reload # New price!
          end

          â†’ This is Phantom read.
          ActiveRecord::Base.transaction do
            users = User.where(active: true)
            # Someone adds a new active user in parallel
            users = User.where(active: true) # New row appears: Phantom Read
          end

     â•°â”ˆâž¤ Repeatable Read
          ðŸ”¸No Dirty Reads â†’ Cannot see uncommitted data
          ðŸ”¸No Non-Repeatable Reads â†’ Rows you read will not change
          ðŸ”¸Phantom Read â†’ A repeated query may return new rows.

          ActiveRecord::Base.transaction(isolation: :repeatable_read) do
            # safer but heavier
          end

     â•°â”ˆâž¤ Serializable (Strictest)
          ðŸ”¸No Dirty Reads
          ðŸ”¸No Non-Repeatable Reads
          ðŸ”¸No Phantom Read

          - Acts like only one transaction is running at a time.
          - But it does not actually queue transactions â€” it uses conflict detection and may throw:
              ActiveRecord::SerializationFailure (could not serialize access)

    âž¤ In SERIALIZABLE isolation level:
        PostgreSQL (and other modern databases) does not queue transactions like a mutex (i.e., one-at-a-time locking).
        Instead, it uses MVCC (Multi-Version Concurrency Control) + conflict detection to simulate serial behavior.

        If it detects that two transactions could have interfered with each other in a way that violates serializability, one of them is rolled back with:
          ActiveRecord::SerializationFailure (could not serialize access due to concurrent update)
        So instead of queueing, it lets both run and detects problems after the fact.

    âž¤ But in a system like IRCTC?
        IRCTC has to prevent overbooking in scenarios like Tatkal, where:
          ðŸ”¸1000+ users try to book 1 ticket at exactly 10:00 AM.
          ðŸ”¸If two people are shown â€œ1 seat availableâ€, both should not book it.

        Such systems often queue at the application level, not just DB.

      Here is how they might ensure strict control:
          
          1.Application-Level Queuing (Real Queueing)
            ðŸ”¸Use Redis queues, Kafka, RabbitMQ, etc.
            ðŸ”¸Requests go into a queue.
            ðŸ”¸A background job or worker processes one at a time.
            ðŸ”¸Others wait in line (just like IRL ticket counters).
            ðŸ”¸This is true queuing, unlike DB isolation levels.

              class BookingWorker
                include Sidekiq::Worker

                def perform(user_id, train_id)
                  ActiveRecord::Base.transaction(isolation: :serializable) do
                    seat = Seat.lock.find_by(train_id: train_id, available: true)
                    raise "No seats" unless seat

                    seat.update!(available: false, user_id: user_id)
                  end
                end
              end
              
            user requests will be enqueue like: BookingWorker.perform_async(current_user.id, train.id)

          2.Optimistic Locking or Pessimistic Locking
              Another technique IRCTC-like systems might use is row-level locking:
               Pessimistic Lock (Rails):
            
               Seat.lock("FOR UPDATE").find(id) => It locks the row until the transaction is done.
              Other users trying to access it will wait (this is queuing via locking).
            
          3.Rate-Limiting & Load Shedding
              Sometimes, the app itself refuses to serve too many concurrent booking attempts, to protect the DB.


    âž¤ What Sidekiq Queue Actually Guarantees? 
        class BookingWorker
          include Sidekiq::Worker

          def perform(user_id, train_id)
            ActiveRecord::Base.transaction(isolation: :serializable) do
              seat = Seat.lock.find_by(train_id: train_id, available: true) 
                #or: seat = Seat.lock("FOR UPDATE").find_by(train_id: train_id, available: true) #Rails convert like this internally.
              raise "No seats" unless seat

              seat.update!(available: false, user_id: user_id)
            end
          end
        end

      Here we might think that: Since Sidekiq jobs already run one by one in a queue, why do we still need transaction(isolation: :serializable) or locking inside them?

        âž¤ Sidekiq guarantees job-level FIFO within a queue.
          BUT:
            It does not guarantee only one job runs at a time across the whole app.
            You can have many workers (threads/processes) processing jobs in parallel.
          
          So if 1000 users click "Book Now", and you do:
            BookingWorker.perform_async(user.id, train.id)
          All 1000 jobs enter Redis queue.
          If you have 10 Sidekiq threads, 10 jobs run simultaneously.

          Each job:
            Grabs a connection.
            Starts a transaction.
            Queries for an available seat.
            Now if two threads find the same seat is available, they may try to book it at the same time. This is what the problem might occur.

 Race Conditions in DB
 ========================
  âž¤ A race condition occurs when two or more concurrent operations access the same data, and at least one of them modifies it, causing unintended or incorrect results.
  Example (Bank Transfer). Assume account has â‚¹10.

    account = Account.find(1)
    account.balance -= 5
    account.save
  
  Now if two threads/users do this at the same time, both fetch balance as â‚¹10 and both save â‚¹5. But it should have been â‚¹5 and â‚¹0.
  This is a race condition: because both read before any write is committed.

  âž¤ There are different ways to solve race conditons:
     
     â•°â”ˆâž¤ Pessimistic Locking (SELECT ... FOR UPDATE)
         ðŸ”¸You lock the row during the transaction, so no other process can read or write until you are done.

          ActiveRecord::Base.transaction do
            account = Account.lock.find(1) # SELECT ... FOR UPDATE
            account.balance -= 5
            account.save!
          end

         ðŸ”¸Useful when you want to process queue-like jobs from DB rows, and skip locked rows.

          ActiveRecord::Base.transaction do
            ticket = Ticket.where(status: 'pending').lock("FOR UPDATE SKIP LOCKED").first
            ticket.update!(status: 'processing')
          end
          
         ðŸ”¸Locks row until transaction ends.
         ðŸ”¸Other transactions trying to SELECT ... FOR UPDATE  or SELECT ... FOR UPDATE SKIP LOCKED must wait or skip.

         ðŸ”¸When to use:
           - High-concurrency writes. For example Inventory, ticket booking, bank balance.
           - You must prevent simultaneous updates. 

     â•°â”ˆâž¤ Atomic Updates using update_counters or raw SQL
         ðŸ”¸An atomic update is a single SQL operation that reads and writes in one step, so there is no chance of race condition.
         ðŸ”¸Unlike the usual read â†’ modify â†’ write, atomic updates do not read the value first in Ruby. They just tell the DB:
               "Go and decrement/increment this value directly!"

          â­ Atomic Way â€” Using update_counters
              User.update_counters(1, coins: -10)
             This generates SQL like: UPDATE users SET coins = coins - 10 WHERE id = 1
            
            It tells the database: "You handle this. Subtract 10 from coins."
            Since this SQL is executed atomically by the DB, no other operation can sneak in between.

          â­ Atomic Way â€” Using Raw SQL (update_all)
              User.where(id: 1).update_all("coins = coins - 10")
             This generates SQL like: UPDATE users SET coins = coins - 10 WHERE id = 1
            
            Works the same as update_counters, but update_all is more flexible â€” you can use expressions, conditions, and more complex SQL.

         ðŸ”¸When to use:
           - You are only modifying a numeric value (e.g., coins, likes, view_count).
           - You do not need to validate or run callbacks.
           - Performance matters â€” it is faster, since it is just one SQL query.
          
          Example:
            Instead of:
              post = Post.find(1)
              post.likes += 1
              post.save
            we should do:
              Post.update_counters(1, likes: 1)
            Or we should do:
              Post.where(id: 1).update_all("likes = likes + 1")


     â•°â”ˆâž¤ Optimistic Locking (lock_version)
          This will allow concurrent reads, but detect conflict at save.
          Detect and prevent conflicting updates when multiple users/processes try to update the same database record at the same time.
          It does not lock the row in the database like pessimistic locking. Instead, it checks:
              "Has this record changed since I last read it?"
          If yes â†’ it throws an error and blocks the update.

          â­ How it Works in Rails:
              Add lock_version to the table. In migration:
                  add_column :users, :lock_version, :integer, default: 0, null: false
                This column keeps track of how many times the row has been updated.

              Rails handle it automatically. We do not need to write special logic. ActiveRecord will:
               ðŸ”¸Read lock_version when loading the object.
               ðŸ”¸Add a condition in the UPDATE like this: UPDATE users SET name = 'Roy', lock_version = 1 WHERE id = 1 AND lock_version = 0

              If the lock_version of row is not 0, this update fails

          Example: 
            Two processes load same record:
              # User A and User B
              user = User.find(1)  # lock_version = 0
            User A updates name:
              user.name = "Roy"
              user.save  # Succeeds â†’ lock_version becomes 1
            Now User B updates email:
              user.email = "test@example.com"
              user.save  # Fails â†’ raises ActiveRecord::StaleObjectError
            Why? Because User Bâ€™s object has lock_version = 0, but DB now has lock_version = 1.

          â­ What Happens Internally?
            - Rails adds this condition to the SQL: WHERE id = 1 AND lock_version = 0
            - If no rows match, Rails knows someone else already changed it.

          â­ What to Do When it Fails?
            - We handle the ActiveRecord::StaleObjectError:
                begin
                  user.save!
                rescue ActiveRecord::StaleObjectError
                  puts "Another process updated this record first. Please reload and try again."
                end

          You can:
            - Reload the record and retry
            - Show a message to user
            - Use conflict resolution strategies (like merging fields)

         ðŸ”¸When to use:
           - Lower chance of collisions.
           - Want to avoid locking but detect and handle conflicts.
           - Ideal for web forms, background workers, or slow UIs.


Deadlocks, Queueing, and Locking Strategies in High-Concurrency Apps
=====================================================================
âž¤ Deadlocks:
   - A deadlock happens when two or more processes wait on each other to release locks, and none can proceed.
     Example: 
        Transaction A locks row 1 â†’ waits for row 2
        Transaction B locks row 2 â†’ waits for row 1
     Both are stuck â†’ deadlock error. ActiveRecord::Deadlocked

  How Rails/DB handles deadlock?
    DB (like PostgreSQL or MySQL) detects deadlocks.
    It kills one transaction with an error: PG::DeadlockDetected: ERROR: deadlock detected


  â­Preventing Deadlocks
  ----------------------
    â•°â”ˆâž¤Best Practices:
        ðŸ”¸Access tables/rows in consistent order: Always lock Train â†’ then Seats
        ðŸ”¸Keep transactions short: Do not perform heavy logic or I/O inside a transaction
        ðŸ”¸Avoid unnecessary locks: Use .select instead of .find if you do not plan to update
        ðŸ”¸Use DB indexes wisely: Without indexes, locks may escalate to table-level
        ðŸ”¸Use advisory locks (Postgres only):
            ActiveRecord::Base.connection.execute("SELECT pg_advisory_lock(12345)")
            # Perform critical work
            ActiveRecord::Base.connection.execute("SELECT pg_advisory_unlock(12345)")
         ðŸ”¹ Note: Advisory locks do not block other operations unless all parties use them.

    â•°â”ˆâž¤App-level Lock( Redis + Sidekiq) And Database-level Lock(Pessimistic Locking):
        ðŸ”¹App-level locking (Redis): Prevents multiple workers from starting booking logic for the same user/train combo.
            lock_key = "booking_lock:user:#{user_id}:train:#{train_id}"
            locked = Redis.current.set(lock_key, "locked", nx: true, ex: 30)

            nx: true => Set only if not already set (non-blocking lock)
            ex: 30 => Auto-expire after 30s (avoids deadlock if job crashes)

        ðŸ”¹DB-level locking (Postgres): Guarantees only one booking can succeed by locking the seat row.

        ðŸ›¡ Use App-Level Lock (Redis) to avoid starting duplicate jobs.
        ðŸ”’ Use DB-Level Lock to guarantee consistency even under race conditions.

         Example:
          class BookingWorker
            include Sidekiq::Worker

            def perform(user_id, train_id)
              lock_key = "booking_lock:user:#{user_id}:train:#{train_id}"
              locked = Redis.current.set(lock_key, "locked", nx: true, ex: 30)
              unless locked
                logger.info "Booking already in progress for user #{user_id}"
                return
              end

              begin
                User.transaction(isolation: :serializable) do
                  seat = Seat.lock("FOR UPDATE SKIP LOCKED").find_by(train_id: train_id, available: true)
                  raise "No seats available" unless seat

                  seat.update!(available: false, user_id: user_id)
                end
              ensure
                Redis.current.del(lock_key)
              end
            end
          end


    â•°â”ˆâž¤Logging and Monitoring Concurrency:
        Detect Deadlocks
          Enable DB logs: log_min_error_statement = 'error' in PostgreSQL
          Check Sidekiq retries (failed jobs)
        Use Monitoring Tools
          New Relic, Datadog, or Skylight to monitor DB load
          Redis + Sidekiq dashboard for queue inspection
